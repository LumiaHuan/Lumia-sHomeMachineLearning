{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(news.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print type(news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18846 18846\n"
     ]
    }
   ],
   "source": [
    "print len(news.data), len(news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print news.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print news.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print news.target_names[news.target[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is already in a random order, so we only have to split data into, for example, 75 percent for training and rest 25 percent for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLT_RATIO = 0.75\n",
    "split_size = int(len(news.data) * SPLT_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = news.data[:split_size]\n",
    "X_test = news.data[split_size:]\n",
    "y_train = news.target[:split_size]\n",
    "y_test = news.target[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency * Inverse Document Frequency\n",
    "\n",
    "**Term Frequency** = #Term in this doc\n",
    "\n",
    "**Inverse Document Frequency** = log (#docs/(1+#docs using this term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Naive Bayes classfier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_countVect = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_hashingVect = Pipeline([\n",
    "        ('vect', HashingVectorizer(non_negative=True)),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidfVect = Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print scores\n",
    "    print \"Mean score:{0:.3f} (+/- {1:.3f})\".format(np.mean(scores), sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = [clf_countVect, clf_hashingVect, clf_tfidfVect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85782493  0.85725657  0.84664367  0.85911382  0.8458477 ]\n",
      "Mean score:0.853 (+/- 0.003)\n",
      "[ 0.75543767  0.77659857  0.77049615  0.78508888  0.76200584]\n",
      "Mean score:0.770 (+/- 0.005)\n",
      "[ 0.84482759  0.85990979  0.84558238  0.85990979  0.84213319]\n",
      "Mean score:0.850 (+/- 0.004)\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To do some regular expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidfVect_new = Pipeline([\n",
    "        ('vect', TfidfVectorizer(token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86100796  0.8718493   0.86203237  0.87291059  0.8588485 ]\n",
      "Mean score:0.865 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_tfidfVect_new, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove some unuseful words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stopword():\n",
    "    result = set()\n",
    "    for line in open('./stopwords_en.txt','r').readlines():\n",
    "        result.add(line.strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidfVect_new_sw = Pipeline([\n",
    "        ('vect', TfidfVectorizer(token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",stop_words=get_stopword())),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88116711  0.89519767  0.88325816  0.89227912  0.88113558]\n",
      "Mean score:0.887 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_tfidfVect_new_sw, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjust the Naive Bayes Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tfidfVect_final = Pipeline([\n",
    "        ('vect', TfidfVectorizer(token_pattern=ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",stop_words=get_stopword())),\n",
    "        ('clf', MultinomialNB(alpha=0.01))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9204244   0.91960732  0.91828071  0.92677103  0.91854603]\n",
      "Mean score:0.921 (+/- 0.002)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_tfidfVect_final, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_evaluate(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print \"Accuracy on training set:\"\n",
    "    print clf.score(X_train, y_train)\n",
    "    print \"Accuracy on testing set:\"\n",
    "    print clf.score(X_test, y_test)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print \"Classfication Report:\"\n",
    "    print metrics.classification_report(y_test, y_pred)\n",
    "    print \"Confusion matrix:\"\n",
    "    print metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.996957690675\n",
      "Accuracy on testing set:\n",
      "0.917869269949\n",
      "Classfication Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91       216\n",
      "          1       0.85      0.85      0.85       246\n",
      "          2       0.91      0.84      0.87       274\n",
      "          3       0.81      0.86      0.83       235\n",
      "          4       0.88      0.90      0.89       231\n",
      "          5       0.89      0.91      0.90       225\n",
      "          6       0.88      0.80      0.84       248\n",
      "          7       0.92      0.93      0.93       275\n",
      "          8       0.96      0.98      0.97       226\n",
      "          9       0.97      0.94      0.96       250\n",
      "         10       0.97      1.00      0.98       257\n",
      "         11       0.97      0.97      0.97       261\n",
      "         12       0.90      0.91      0.91       216\n",
      "         13       0.94      0.95      0.95       257\n",
      "         14       0.94      0.97      0.95       246\n",
      "         15       0.90      0.96      0.93       234\n",
      "         16       0.91      0.97      0.94       218\n",
      "         17       0.97      0.99      0.98       236\n",
      "         18       0.95      0.91      0.93       213\n",
      "         19       0.86      0.78      0.82       148\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4712\n",
      "\n",
      "Confusion matrix:\n",
      "[[190   0   0   0   1   0   0   0   0   1   0   0   0   1   0   9   2   0\n",
      "    0  12]\n",
      " [  0 208   5   3   3  13   4   0   0   0   0   1   3   2   3   0   0   1\n",
      "    0   0]\n",
      " [  0  11 230  22   1   5   1   0   1   0   0   0   0   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   6   6 202   9   3   4   0   0   0   0   0   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   3   4 208   1   5   0   0   0   2   0   5   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   9   2   2   1 205   0   1   1   0   0   0   0   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   3  10   6   0 199  14   1   2   0   1   5   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   1   1   1   1   0   6 257   4   1   0   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   1   2 221   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   2 236   5   0   1   3   0   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0 256   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0 254   0   1   0   0   3   0\n",
      "    1   0]\n",
      " [  0   1   0   1   5   1   3   1   0   2   1   1 197   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   1   1   0   0   0   0   0   0   2   2 245   3   0   1   0\n",
      "    0   1]\n",
      " [  0   2   0   0   1   0   0   1   0   0   0   0   0   1 238   0   1   0\n",
      "    1   1]\n",
      " [  1   0   1   2   0   0   0   1   0   0   0   1   1   0   1 225   0   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   1   0   1   0   0   1   0   0   0   0 212   0\n",
      "    2   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 234\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   2   1   1   0   1   7   3\n",
      "  193   4]\n",
      " [  9   0   0   0   0   1   0   0   0   1   0   0   0   0   0  13   4   1\n",
      "    4 115]]\n"
     ]
    }
   ],
   "source": [
    "train_evaluate(clf_tfidfVect_final, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
